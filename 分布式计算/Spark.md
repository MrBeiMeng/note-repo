## Spark ç¬”è®°

**Spark æ˜¯ä¸€ç§åŸºäºå†…å­˜çš„å¿«é€Ÿã€é€šç”¨ã€å¯æ‰©å±•çš„å¤§æ•°æ®åˆ†æè®¡ç®—å¼•æ“**

2009 - è‡³ä»Š





### å¯¹æ¯”Hadoop

Hadoop æ˜¯ä¸€ä¸ªæ‰¹å¤„ç†å·¥å…·ï¼Œç”± java è¯­è¨€ç¼–å†™

Spark æ˜¯ä¸€ä¸ªæ‰¹æµä¸€ä½“çš„å¤„ç†å·¥å…·ï¼ŒåŸºäºå†…å­˜ï¼Œæ‰€ä»¥ä¼šæ¯”hadoopå¿«

![image-20220915214022209](https://ccurj.oss-cn-beijing.aliyuncs.com/mac-typoraimage-20220915214022209.png)

**ä¸€æ¬¡æ€§æ•°æ®è®¡ç®—ä¾‹å›¾**

> æ¡†æ¶åœ¨å¤„ç†æ•°æ®çš„æ—¶å€™ï¼Œä¼šä»å­˜å‚¨è®¾å¤‡ä¸­è¯»å–æ•°æ®ï¼Œè¿›è¡Œé€»è¾‘æ“ä½œï¼Œç„¶åå°†å¤„ç†çš„ç»“æœé‡æ–°å­˜å‚¨åˆ°ä»‹è´¨ä¸­ã€‚ä½†æ˜¯å¦‚æ­¤æ“ä½œä¸€æ—¦é‡åˆ°æ•°æ®è¦é‡å¤ä¿®æ”¹ï¼Œå¤§é‡çš„IOæ“ä½œä¾¿ä¼šå½±å“æ•´ä½“çš„é€Ÿåº¦ã€‚Spark å…¶å®å°±æ˜¯åœ¨é‡å¤æ“ä½œçš„è¿‡ç¨‹ä¸­é™¤å»äº†ä¿å­˜åˆ°ç£ç›˜çš„é‚£ä¸€æ­¥ï¼Œç›´æ¥æ”¾åˆ°å†…å­˜è¿›è¡Œå¤„ç†ã€‚

![image-20220915200803410](https://ccurj.oss-cn-beijing.aliyuncs.com/mac-typoraimage-20220915200803410.png)



**ä¸èƒ½å®Œå…¨æ›¿ä»£ Hadoop**

- åœ¨è®¡ç®—å±‚é¢ï¼ŒSpark ç›¸æ¯”è¾ƒ Mr(MapReduce) æœ‰å·¨å¤§çš„æ€§èƒ½ä¼˜åŠ¿ï¼Œä½†è‡³ä»Šä»ç„¶æœ‰è®¸å¤šè®¡ç®—å·¥å…·åŸºäº MR æ¡†æ¶ï¼Œæ¯”å¦‚éå¸¸æˆç†Ÿçš„ Hiveã€‚
- Spark ä»…åšè®¡ç®—ï¼Œè€Œ Hadoop ç”Ÿæ€åœˆä¸ä»…æœ‰è®¡ç®—( Mr ) ä¹Ÿæœ‰å­˜å‚¨( HDFS ) å’Œ èµ„æºç®¡ç†è°ƒåº¦ (YARN) , HDFSå’ŒYARNä»æ˜¯è®¸å¤šå¤§å¤šæ•°ä½“ç³»çš„æ ¸å¿ƒæ¶æ„ã€‚





### æ ¸å¿ƒæ¨¡å—

![image-20220915201703053](https://ccurj.oss-cn-beijing.aliyuncs.com/mac-typoraimage-20220915201703053.png)

- **Spark Core** æä¾›æœ€åŸºç¡€æ ¸å¿ƒçš„åŠŸèƒ½ï¼Œå…¶ä»–æ¨¡å—éƒ½åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œæ‰©å±•
- **Spark SQL** æ“ä½œç»“æ„åŒ–æ•°æ®çš„æ¨¡å—
- **Spark Streaming** å¯¹å®æ—¶æ•°æ®/æµå¼æ•°æ®è¿›è¡Œæ“ä½œçš„æ¨¡å—
- **Spark MLlib** æœºå™¨å­¦ä¹ æ“ä½œ
- **Spark Graphx** å›¾å½¢æŒ–æ˜è®¡ç®—



### **è¿è¡Œæ¨¡å¼**

- æœ¬åœ°æ¨¡å¼ (å•æœº) - **Local**  ä¸€èˆ¬ç”¨æ¥å¼€å‘å’Œæµ‹è¯• 

  > æœ¬åœ°æ¨¡å¼å°±æ˜¯ä»¥ä¸€ä¸ªç‹¬ç«‹çš„è¿›ç¨‹ï¼Œé€šè¿‡å…¶å†…éƒ¨çš„å¤šä¸ªçº¿ç¨‹æ¥æ¨¡æ‹Ÿæ•´ä¸ª Spark è¿è¡Œæ—¶ç¯å¢ƒ

- Standaloneæ¨¡å¼ (é›†ç¾¤) - **HDFS**

  > Spark ä¸­çš„å„ä¸ªè§’è‰²ä»¥ç‹¬ç«‹è¿›ç¨‹çš„å½¢å¼å­˜åœ¨ï¼Œå¹¶ç»„æˆSparké›†ç¾¤ç¯å¢ƒ

- Hadoop YARNæ¨¡å¼ (é›†ç¾¤)

  > Spark ä¸­çš„å„ä¸ªè§’è‰²è¿è¡Œåœ¨Kubernetesçš„å®¹å™¨å†…éƒ¨ï¼Œå¹¶ç»„æˆ Spark é›†ç¾¤ç¯å¢ƒ

  

  Kubernetes æ¨¡å¼ï¼Œäº‘æœåŠ¡æ¨¡å¼



### **æ¶æ„è§’è‰²**

Spark ä¸­ç”±4ç±»è§’è‰²ç»„æˆæ•´ä¸ªSpark çš„è¿è¡Œæ—¶ç¯å¢ƒ

- Master
- Worker
- Driver
- Executor



### å­¦ä¹ ç¯å¢ƒæ­å»º

ä¸‰å°Linux è™šæ‹ŸæœºæœåŠ¡å™¨ - æœ‰äº‘çš„ï¼Œä¸éœ€è¦æ­å»º

â€‹	node1: Master(HDFS\YARN\Spark) å’Œ Worker (HDFS\YARN\Spark)

â€‹	node2: Worker(HDFS\YARN\Spark)

â€‹	node3:Worker(HDFS\YARN\Spark) å’Œ Hive

 ç½‘æ®µ192.168.88.0

æ­å»ºç¯å¢ƒæ•™ç¨‹ï¼šã€Spark pythonã€‘https://www.bilibili.com/video/BV1Jq4y1z7VP?p=13&vd_source=daf77da3a61c83fe6e450deea76785f6



### PySpark å’Œ Spark

PySpark æ˜¯ Spark çš„ä¸€ç§åŸºäº python çš„æ“ä½œæ–¹å¼ï¼Œç¨‹åºè°ƒè¯•å¥½è¦ä¸Šä¼ åˆ° Spark å»è¿è¡Œã€‚



### æœ¬æœºå¼€å‘ç¯å¢ƒæ­å»º

```python
pip install pyspark pyhive jieba
```

å¼€å‘å…¥å£

```python
conf = SparkConf().setAppName(appName).setMaster(master)
sc = SparkContext(conf= conf)
```





### Spark On Yarn æ¨¡å¼æ­å»º

**1 æœ¬è´¨**

- Master è§’è‰²ç”± YARN çš„ ResourceManage æ‹…ä»»ã€‚ã€ç®¡ç†ã€‘

- Worker è§’è‰²ç”± YARN çš„ NodeManageer æ‹…ä»»ã€‚ ã€ç®¡ç†ã€‘

- Driver è§’è‰²è¿è¡Œåœ¨ YARNå®¹å™¨ å†… æˆ– æäº¤ä»»åŠ¡çš„å®¢æˆ·ç«¯è¿›ç¨‹ã€‚ã€ä»»åŠ¡è®¡ç®—ã€‘

- çœŸæ­£å¹²æ´»çš„ Executor è¿è¡Œåœ¨ YARN æä¾›çš„å®¹å™¨å†…ã€‚ã€è¿è¡Œä»»åŠ¡ã€‘



**2 å‡†å¤‡**

1. éœ€è¦ Yarn é›†ç¾¤
2. éœ€è¦ Spark å®¢æˆ·ç«¯å·¥å…·ï¼Œæ¯”å¦‚ spark-submit, å¯ä»¥å°†Spark ç¨‹åºæäº¤åˆ° YARN ä¸­
3. éœ€è¦è¢«æäº¤çš„ä»£ç ç¨‹åºï¼Œ è¦è‡ªå·±å†™ã€‚



**3 ç¯å¢ƒæ­å»º**

æŒ‡è·¯ï¼šğŸ‘‰[ã€é»‘é©¬ç¨‹åºå‘˜Sparkå…¨å¥—è§†é¢‘æ•™ç¨‹ã€‘](https://www.bilibili.com/video/BV1Jq4y1z7VP?p=24&vd_source=daf77da3a61c83fe6e450deea76785f6)

 

**4 ä¸¤ç§éƒ¨ç½²æ¨¡å¼**

Cluster æ¨¡å¼(è¿è¡Œæ•ˆç‡é«˜) ä¸ Clientæ¨¡å¼(å¯ä»¥æŸ¥çœ‹æ—¥å¿—)